---
icon: pen-to-square
date: 2024-08-01
category:
  - AI
tag:
  - tts
  - voice recognition
  - nlp
---
# Coqui.ai TTS

### [web demo](https://huggingface.co/spaces/coqui/xtts)

## TTS Performance
![Performance from git](https://raw.githubusercontent.com/coqui-ai/TTS/main/images/TTS-performance.png)
Underlined "TTS*" and "Judy*" are internal ğŸ¸TTS models that are not released open-source. They are here to show the potential. Models prefixed with a dot (.Jofish .Abe and .Janice) are real human voices.

## Features
- é«˜æ•ˆèƒ½æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Œç”¨æ–¼æ–‡æœ¬åˆ°èªéŸ³ï¼ˆText2Speechï¼‰ä»»å‹™ã€‚
- æ”¯æ´ Text2Spec æ¨¡å‹ï¼ˆTacotronã€Tacotron2ã€Glow-TTSã€SpeedySpeechï¼‰ã€‚
- èªè€…ç·¨ç¢¼å™¨ï¼ˆSpeaker Encoderï¼‰è¨ˆç®—èªè€…åµŒå…¥ï¼ˆspeaker embeddingsï¼‰ã€‚
- å¤šç¨® Vocoder æ¨¡å‹ï¼ˆMelGANã€Multiband-MelGANã€GAN-TTSã€ParallelWaveGANã€WaveGradã€WaveRNNï¼‰ã€‚
- æ”¯æ´å¤šèªè¨€ TTSã€‚

## Installation
ğŸ¸TTS is tested on Ubuntu 18.04 with python >= 3.9, < 3.12..

Using docker is relatively simple.

**Dockerfile :**
``` Dockerfile
# COPY . .
# ä½¿ç”¨å®˜æ–¹çš„ Python é¡åƒä½œç‚ºåŸºç¤é¡åƒ
FROM python:3.9-slim

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

RUN apt-get update && \
apt-get install -y --no-install-recommends \
build-essential \
libsndfile1-dev \
&& rm -rf /var/lib/apt/lists/*

RUN pip install --upgrade pip
RUN pip install TTS soundfile

# EXPOSE 5000

# è¨­å®šå…¥å£é»ï¼ˆå¦‚æœæœ‰éœ€è¦çš„è…³æœ¬ï¼‰
# ENTRYPOINT ["python", "your_script.py"]

# æˆ–é€²å…¥äº’å‹•å¼ç’°å¢ƒ
CMD ["bash"]
```

**åŸ·è¡Œ :** 
- ``docker build -t coqui-tts .``
- ``docker run -it --rm -v /path/to/local/dir:/app/data coqui-tts``
    - /path/to/local/dir -> æ›¿æ›æˆè‡ªå·±çš„è·¯å¾‘
- with gpu -> `` docker run -it --gpus all -v /path/to/local/dir:/app coqui-tts``

**unsupport in windows([ref](https://github.com/coqui-ai/TTS/issues/2075))**

## Sample code

### List available ğŸ¸TTS models
```python
models = TTS().list_models().list_models()
for model in models:
    print(model)
```


### Running a multi-speaker and multi-lingual model
```python
import torch
from TTS.api import TTS

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to('cpu')
text = "Hello world."
wav = tts.tts(text="Hello world!", speaker_wav='speaker.wav', language="en")
```

### Example voice conversion
```python
import torch
from TTS.api import TTS

tts = TTS(model_name="voice_conversion_models/multilingual/vctk/freevc24").to("cpu")
tts.voice_conversion_to_file(source_wav="a.wav", target_wav="b.wav", file_path="output.wav")
```

## Result

### With ``tts_models/multilingual/multi-dataset/xtts_v2`` model:

- **eng text : Thanks for reading this article. I hope you learned something.**

<audio controls>
    <source src="@source/ai/tts/result/coqui-tts-en-result.wav" type="audio/mpeg">
    Your browser does not support the audio tag.
</audio>

- **zh text : æ„Ÿè¬æ‚¨é–±è®€æœ¬æ–‡ã€‚æˆ‘å¸Œæœ›ä½ å­¸åˆ°äº†ä¸€äº›æ±è¥¿ã€‚**

<audio controls>
    <source src="@source/ai/tts/result/coqui-tts-zh-result.wav" type="audio/mpeg">
    Your browser does not support the audio tag.
</audio>

###  With ``voice_conversion_models/multilingual/vctk/freevc24`` model:

<audio controls>
    <source src="@source/ai/tts/result/coqui-tts-convert-result.wav" type="audio/mpeg">
    Your browser does not support the audio tag.
</audio>

## differences between the major open source voice cloning projects
åœ¨[é€™ç¯‡è¨è«–](https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/)ä¸­ï¼Œå¤§å®¶å°æ–¼ä¸€äº›ä¸»è¦çš„é–‹æºèªéŸ³å…‹éš†é …ç›®é€²è¡Œäº†æ¯”è¼ƒï¼ŒåŒ…æ‹¬Coquiã€Tortoiseã€Barkç­‰ã€‚ä»¥ä¸‹æ˜¯æ•´ç†å‡ºçš„ä¸»è¦é‡é»å’Œæ¯”è¼ƒï¼š

### ElevenLabs
- é›–ç„¶è³ªé‡æœ€å¥½ï¼Œä½†ä¸æ˜¯é–‹æºçš„ï¼Œä¹Ÿä¸æ˜¯å…è²»çš„ã€‚

### Coqui
- åŸºæ–¼Tacotron2å’ŒVITSæ¨¡å‹ï¼Œæ”¯æŒå¤šèªè¨€ï¼Œå¯ä»¥è‡ªç”±èª¿æ•´èªéŸ³ï¼Œä½†éœ€è¦å¤§é‡æ•¸æ“šå’Œè¨“ç·´ã€‚
- é–‹æºä½†æŸäº›æ¨¡å‹å¯èƒ½ä¸å…è¨±å•†æ¥­ä½¿ç”¨ã€‚
- è¢«èªç‚ºè³ªé‡ä¸å¦‚ElevenLabsï¼Œä½†å› ç‚ºæ˜¯é–‹æºçš„ä¸”æœ‰å•†æ¥­APIï¼Œå¯ä»¥é€²è¡Œå¾®èª¿å’Œè¨“ç·´ã€‚

### Tortoise
- ä½¿ç”¨TransformeræŠ€è¡“ï¼Œæ¯”è¼ƒç©©å®šï¼Œæœ‰äº›åˆ†æ”¯å¯ä»¥é€²è¡Œå¾®èª¿ã€‚
- èƒ½å¤ åœ¨è‰¯å¥½æ•¸æ“šé›†ä¸‹æœ‰å„ªç§€è¡¨ç¾ï¼Œä½†é€Ÿåº¦éå¸¸æ…¢ã€‚

### Bark
- ä½¿ç”¨æ›´ç¾ä»£çš„æŠ€è¡“ï¼Œæ½›åŠ›å¾ˆå¤§ï¼Œä½†ç›®å‰ç©©å®šæ€§è¼ƒå·®ï¼Œè¨“ç·´ä»£ç¢¼ä¸å…¬é–‹ã€‚
- ç¾éšæ®µå¯èƒ½ä¸æ˜¯æœ€ä½³é¸æ“‡ã€‚

### å…¶ä»–é–‹æºé …ç›®
- XTTS-v2ç­‰é …ç›®æä¾›äº†å…¶ä»–é¸æ“‡ï¼Œä½†ç›®å‰é€™äº›é …ç›®çš„æˆç†Ÿåº¦å’Œæ€§èƒ½èˆ‡ElevenLabsç­‰å•†æ¥­è§£æ±ºæ–¹æ¡ˆé‚„æœ‰å·®è·ã€‚

### çµè«–
- é–‹æºé …ç›®å¦‚Coquiå’ŒTortoiseå¯ä»¥é€²è¡Œè‡ªè¨‚å’Œèª¿æ•´ï¼Œä½†åœ¨è³ªé‡å’Œä½¿ç”¨ä¾¿æ·æ€§ä¸Šå°šç„¡æ³•èˆ‡ElevenLabsç­‰å•†æ¥­é …ç›®ç«¶çˆ­ã€‚
- Barkå’Œå…¶ä»–æ–°èˆˆæŠ€è¡“æœ‰æ½›åŠ›ï¼Œä½†ä»è™•æ–¼æ—©æœŸé–‹ç™¼éšæ®µã€‚
- ç›®å‰å¸‚å ´ä¸Šå°é«˜è³ªé‡èªéŸ³å…‹éš†çš„éœ€æ±‚ä»æœªè¢«å®Œå…¨æ»¿è¶³ï¼Œå°¤å…¶æ˜¯é–‹æºé ˜åŸŸã€‚

## Reference
- [website](https://coqui.ai/)
- [coqui-ai/TTS github](https://github.com/coqui-ai/TTS?tab=readme-ov-file)
- [daswer123/xtts-webui github](https://github.com/daswer123/xtts-webui)
- [reddit-What are the differences between the major open source voice cloning projects?](https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/)