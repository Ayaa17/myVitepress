---
icon: pen-to-square
date: 2025-06-10
category:
  - AI
tag:
  - mcp
  - llm
---

# MCP Server

This repository is a collection of reference implementations for the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction), as well as references to community built servers and additional resources.

The servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources. Each MCP server is implemented with either the Typescript [MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk) or [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk).

## Difference between ToolCall

MCP is built on top of tool calling. The tool calls need to be executed somewhere, and MCP represents the first major attempt at a â€œportable tool interfaceâ€
MCP å°±æ˜¯æŠŠ `åŸ·è¡Œå·¥å…·çš„éšæ®µ` æŠ½é›¢å‡ºä¾†ï¼Œæ”¹ç”± MCP Server ä¾†åŸ·è¡Œ

![mcp-diff](./images/mcp-diff.png)

## MCP Server transport mode

ç•¶å‰ **MCP (Model Context Protocol) Server** æ”¯æ´çš„ä¸‰ç¨®å¸¸è¦‹ **transport modeï¼ˆå‚³è¼¸æ¨¡å¼ï¼‰** å„æœ‰ç‰¹é»ï¼Œä¸»è¦ç”¨æ–¼è™•ç†ã€Œæ¨¡å‹èˆ‡ä½¿ç”¨è€…ä¹‹é–“ã€çš„é›™å‘è³‡è¨Šæµï¼Œç‰¹åˆ¥æ˜¯åœ¨**æŒçºŒæ€§å›æ‡‰ã€ä¸²æµç”Ÿæˆ**çš„å ´æ™¯ä¸­éå¸¸é‡è¦ã€‚ä»¥ä¸‹æ˜¯ä¸‰ç¨®æ¨¡å¼çš„ä»‹ç´¹èˆ‡æ¯”è¼ƒï¼š

### 1. `stdio`ï¼ˆæ¨™æº–è¼¸å…¥/è¼¸å‡ºï¼‰

ä½¿ç”¨ OS çš„æ¨™æº–è¼¸å…¥ï¼ˆstdinï¼‰èˆ‡æ¨™æº–è¼¸å‡ºï¼ˆstdoutï¼‰ä¾†èˆ‡æ¨¡å‹æˆ–ä¸‹æ¸¸å…ƒä»¶é€šè¨Šã€‚é€™ç¨®æ¨¡å¼é€šå¸¸ç”¨æ–¼åµŒå…¥å¼ç’°å¢ƒã€CLI å·¥å…·ï¼Œæˆ–èˆ‡å­è¡Œç¨‹ï¼ˆsubprocessï¼‰äº’å‹•çš„æƒ…å¢ƒã€‚

#### âœ… å„ªé»

- **ç°¡å–®ç©©å®š**ï¼šä¸éœ€ HTTP serverï¼Œç³»çµ±è³‡æºæ¶ˆè€—ä½ã€‚
- **é©ç”¨å­è¡Œç¨‹æ¶æ§‹**ï¼šä¾‹å¦‚èˆ‡ LLM binary äº’å‹•ï¼ˆå¦‚ llama.cppï¼‰ã€‚
- **æ˜“æ–¼é™¤éŒ¯**ï¼šç›´æ¥æŸ¥çœ‹ stdout/stderr è¨Šæ¯ã€‚

#### âš ï¸ ç¼ºé»

- ç„¡åŸç”Ÿä¸²æµï¼šéœ€é€é buffer æˆ–åˆ†æ®µè™•ç†ã€‚
- ä¸é©åˆå¤šäººä¸¦ç™¼ï¼šæ¯å€‹å¯¦ä¾‹åªæ”¯æ´å–®ä¸€é€šé“ã€‚
- è·¨å¹³å°è™•ç†ç•¥ç‚ºè¤‡é›œã€‚

### 2. `sse`ï¼ˆServer-Sent Eventsï¼‰

åŸºæ–¼ HTTP çš„å–®å‘äº‹ä»¶ä¸²æµæ¨™æº–ï¼Œç”±ä¼ºæœå™¨æŒçºŒæ¨é€è¨Šæ¯åˆ°ç”¨æˆ¶ç«¯ï¼Œå¸¸ç”¨æ–¼ LLM æ–‡å­—ç”Ÿæˆçš„é€å­—å›å‚³ï¼ˆé¡ä¼¼ OpenAI çš„ `stream: true`ï¼‰ã€‚

#### âœ… å„ªé»

- **å³æ™‚ä¸²æµ**ï¼šæ”¯æ´é€å­—ã€é€æ®µè¼¸å‡ºã€‚
- **ç›¸å®¹æ€§å¥½**ï¼šç€è¦½å™¨èˆ‡ä¸»æµå‰ç«¯æ¡†æ¶åŸç”Ÿæ”¯æ´ã€‚
- **å»ºç«‹æˆæœ¬ä½**ï¼šä½¿ç”¨ HTTP/1.1ï¼Œç„¡éœ€ WebSocketã€‚

#### âš ï¸ ç¼ºé»

- å–®å‘é€šè¨Šï¼ˆä¼ºæœå™¨ âœ å®¢æˆ¶ç«¯ï¼‰ï¼Œä¸æ”¯æ´ç”¨æˆ¶ç«¯ä¸»å‹•å›è¦†ã€‚
- å°æ–¼éŒ¯èª¤/é‡é€£è™•ç†éœ€è‡ªè¨‚æ©Ÿåˆ¶ã€‚

### 3. `streamable`ï¼ˆé¡ä¼¼é›™å‘æµï¼šgRPC æˆ–è‡ªå®šç¾©æµå¼å°åŒ…ï¼‰

æ³›æŒ‡**æ”¯æ´é›™å‘æˆ–æŒçºŒè³‡æ–™æµ**çš„é€šè¨Šå”å®šï¼Œå¦‚ï¼š

- gRPC Streamï¼ˆé›™å‘æµï¼‰
- WebSocket
- HTTP/2 + chunked transfer
- è‡ªå®šç¾© framing protocolï¼ˆå¦‚ LangChain's `Streamable` interfaceï¼‰

æ­¤æ¨¡å¼å…è¨±æ¨¡å‹èˆ‡å®¢æˆ¶ç«¯åœ¨æ¨ç†éç¨‹ä¸­æŒçºŒäº¤æ›è¨Šæ¯ï¼ˆä¾‹å¦‚å‚³è¼¸èªéŸ³ç‰‡æ®µã€ç•«é¢ frameã€äº¤éŒ¯æ§åˆ¶æŒ‡ä»¤ç­‰ï¼‰ã€‚

#### âœ… å„ªé»

- **é›™å‘é€šè¨Š**ï¼šæ”¯æ´ client â†” server çš„äº’å‹•ã€‚
- **é©ç”¨è¤‡é›œä»»å‹™**ï¼šå¦‚èªéŸ³è½‰æ–‡å­—ã€éŠæˆ²ç’°å¢ƒæ§åˆ¶ã€‚
- **å»¶å±•æ€§é«˜**ï¼šæ”¯æ´å¤šæ¨¡æ…‹èˆ‡ç•°æ­¥è³‡æ–™æµã€‚

#### âš ï¸ ç¼ºé»

- é–‹ç™¼è¼ƒè¤‡é›œï¼šéœ€è™•ç†è¨Šæ¯ framingã€é€£ç·šä¸­æ–·èˆ‡é‡é€£ã€‚
- ç›¸ä¾æ–¼åº•å±¤å”å®šï¼ˆå¦‚ HTTP/2ã€gRPCã€WebSocketï¼‰ã€‚

### ğŸ“Š æ¨¡å¼æ¯”è¼ƒè¡¨

| æ¨¡å¼         | ä¸²æµæ”¯æ´ | é›™å‘é€šè¨Š   | è¼•é‡æ€§ | é©åˆç”¨é€”                        |
| ------------ | -------- | ---------- | ------ | ------------------------------- |
| `stdio`      | âŒ é™åˆ¶  | âœ…ï¼ˆåŒæ­¥ï¼‰ | âœ…     | CLI, å­è¡Œç¨‹æ¨¡å‹                 |
| `sse`        | âœ… å–®å‘  | âŒ         | âœ…     | Web å‰ç«¯æ–‡å­—ä¸²æµ                |
| `streamable` | âœ… é›™å‘  | âœ…         | âš ï¸     | å¤šæ¨¡æ…‹ä»»å‹™ã€èªéŸ³ã€äº’å‹• AI Agent |

---

[!WARNING]  
Generated from AI

## MCP Server é–‹ç™¼èªè¨€èˆ‡åŸ·è¡Œæ–¹å¼

- ğŸ’» Use [modelcontextprotocol](https://github.com/modelcontextprotocol) SDKs to start building:

  - [TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)
  - [Python SDK](https://github.com/modelcontextprotocol/python-sdk)
  - [Java SDK](https://github.com/modelcontextprotocol/java-sdk)
  - [Kotlin SDK](https://github.com/modelcontextprotocol/kotlin-sdk)
  - [C# SDK](https://github.com/modelcontextprotocol/csharp-sdk)

- Use [FastMCP](https://github.com/jlowin/fastmcp):
  - FastMCP is the standard framework for working with the Model Context Protocol. FastMCP 1.0 was incorporated into the official low-level Python SDK, and FastMCP 2.0 (this project) provides a complete toolkit for working with the MCP ecosystem.
  - openai-agent æœ‰åŒ… FastMCP v1

### MCP server sample code

#### stdio example

```python
from fastmcp import FastMCP

mcp = FastMCP("Demo ğŸš€")

@mcp.tool
def add(a: int, b: int) -> int:
    """Add two numbers"""
    return a + b

if __name__ == "__main__":
    mcp.run()
```

#### sse example

[server.py](https://github.com/openai/openai-agents-python/blob/main/examples/mcp/sse_example/server.py)

```python
import random

import requests
from mcp.server.fastmcp import FastMCP

# Create server
mcp = FastMCP("Echo Server")


@mcp.tool()
def add(a: int, b: int) -> int:
    """Add two numbers"""
    print(f"[debug-server] add({a}, {b})")
    return a + b


@mcp.tool()
def get_secret_word() -> str:
    print("[debug-server] get_secret_word()")
    return random.choice(["apple", "banana", "cherry"])


@mcp.tool()
def get_current_weather(city: str) -> str:
    print(f"[debug-server] get_current_weather({city})")

    endpoint = "https://wttr.in"
    response = requests.get(f"{endpoint}/{city}")
    return response.text


if __name__ == "__main__":
    mcp.run(transport="sse")
```

#### streamablehttp example

[server.py](https://github.com/openai/openai-agents-python/blob/main/examples/mcp/streamablehttp_example/server.py)

```python
import random
import requests
from mcp.server.fastmcp import FastMCP

# Create server
mcp = FastMCP("Echo Server")


@mcp.tool()
def add(a: int, b: int) -> int:
    """Add two numbers"""
    print(f"[debug-server] add({a}, {b})")
    return a + b


@mcp.tool()
def get_secret_word() -> str:
    print("[debug-server] get_secret_word()")
    return random.choice(["apple", "banana", "cherry"])


@mcp.tool()
def get_current_weather(city: str) -> str:
    print(f"[debug-server] get_current_weather({city})")

    endpoint = "https://wttr.in"
    response = requests.get(f"{endpoint}/{city}")
    return response.text


if __name__ == "__main__":
    mcp.run(transport="streamable-http")
```

## MCP Servers

These servers aim to demonstrate MCP features and the TypeScript and Python SDKs.

- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools
- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage
- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls
- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories
- **[Memory](src/memory)** - Knowledge graph-based persistent memory system
- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences
- **[Time](src/time)** - Time and timezone conversion capabilities

MORE SERVERS:

- [modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)
- [punkpeye/awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers)

## MCP Server Development and Debug Tool

å®˜æ–¹æä¾›äº†ä¸€å¥—éå¸¸å¯¦ç”¨çš„æ¸¬è©¦å·¥å…· [modelcontextprotocol/inspector](https://github.com/modelcontextprotocol/inspector)ã€‚é€™å€‹å·¥å…·å¯ä»¥è®“ä½ ç›´æ¥èˆ‡ MCP Server äº’å‹•ï¼Œæ‰‹å‹•ç™¼é€è«‹æ±‚ã€æŸ¥çœ‹å›æ‡‰ï¼Œæ–¹ä¾¿å¿«é€Ÿ debugã€‚(æ²’æœ‰ä½¿ç”¨ä»»ä½• LLM çš„éƒ¨åˆ†)

To inspect an MCP server implementation, there's no need to clone this repo. Instead, use npx. For example, if your server is built at build/index.js:

```bash
npx @modelcontextprotocol/inspector node build/index.js

# OR
# Pass arguments only
npx @modelcontextprotocol/inspector node build/index.js arg1 arg2
```

## LLM support (MCP Client)

[Example Clients - Model Context Protocol](https://modelcontextprotocol.io/clients)

## Reference

- [openai/openai-agents-python examples](https://github.com/openai/openai-agents-python/tree/main/examples/mcp)
- [modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)
- [MCP é–‹ç™¼å¯¦æˆ°æ‰‹å†Šï¼šSSEã€STDIOã€Toolã€Resource ä¸€æ¬¡ææ‡‚](https://oalieno.tw/posts/mcp)
- [reddit - difference_between_mcp_and_traditional_toolcall](https://www.reddit.com/r/mcp/comments/1jphxuu/difference_between_mcp_and_traditional_toolcall/)
- [punkpeye/awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers)
