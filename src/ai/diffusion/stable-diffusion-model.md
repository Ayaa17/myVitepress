---
icon: pen-to-square
date: 2025-01-17
category:
  - AI
tag:
  - stable diffusion
---

# Stable Diffusion Model

Model 有各種改進變體等等差異。

## Stable Diffusion Base Model

Base Model 是不同版本的 Stable Diffusion 或其改進與變體，針對不同的應用場景、性能優化和創意需求進行設計和微調。以下是對這些模型的分類與特性差異的詳細解釋：

### **1. 核心版本差異**

Stable Diffusion 的核心版本可以分為以下幾代，每一代都有新的改進：

### **1.1 SD 1.x 系列**

- **SD 1.4**: 最早公開的穩定版本，用於廣泛的文本到圖像生成。
- **SD 1.5**: 在 1.4 基礎上進行改進，生成質量更好，噪聲消除更強。
  - **SD 1.5 LCM**: 針對 **低記憶體消耗（Low Consumption Memory）** 的優化版本，適合硬件資源有限的用戶。
  - **SD 1.5 Hyper**: 進一步加強生成細節與質感的版本，適合更高分辨率的輸出需求。

### **1.2 SD 2.x 系列**

- **SD 2.0**: 將文本嵌入（text embedding）架構從 CLIP 改進到 OpenCLIP，生成質量提升，支持 768x768 的輸出分辨率。
- **SD 2.1**: 修正了 SD 2.0 的一些問題，生成效果更穩定，支持更高分辨率和更好的細節處理。

### **1.3 SDXL 系列**

- **SDXL 1.0**: 是 Stable Diffusion 的大規模擴展版本，模型參數超過 3.5B，能生成細節極其豐富、逼真的高分辨率圖像。
- **SDXL Lightning**: SDXL 1.0 的精簡與加速版，速度更快，但可能略微犧牲細節。
- **SDXL Hyper**: 在 SDXL 1.0 的基礎上，進一步提升細節控制和分辨率表現。

### **1.4 SD 3.x 系列**

- **SD 3**: 下一代 Stable Diffusion，改進了擴散模型的架構，生成質量和速度顯著提升。
- **SD 3.5 Medium**/**SD 3.5 Large**/**SD 3.5 Large Turbo**:
  - 不同版本針對速度、細節和資源消耗進行調整。
  - **Turbo** 強調高效運行，適合對速度要求較高的場景。

---

### **2. 特殊用途模型**

以下模型針對特定應用場景進行了微調：

- **Aura Flow**: 專注於藝術風格與氛圍生成，適合抽象藝術與概念設計。
- **Pony**/**Pony: People's Works**/**Ohogao SDXL LOR Pony**:
  - 為生成 **My Little Pony** 風格的圖像專門訓練的模型。
- **PixArt Σ**/**PixArt A**: 針對 **動漫風格** 微調，適合動畫設計與角色生成。
- **Hunyuan 1**/**Hunyuan Video**: 強化視頻生成能力的變體模型。
- **Kolors**/**LTXV**/**Lumina**: 注重色彩與光影效果，適合時尚設計與攝影模擬。
- **Dajiejiekong**: 中文語義優化的模型，適合生成中文相關內容。

---

### **3. 多模態與視頻生成**

這些模型適合跨模態（如視頻生成）或特殊場景需求：

- **CogVideoX**: 專為視頻生成設計，適合從文本生成連續畫面。
- **Hunyuan Video**: 針對視頻穩定性和高質量的多幀生成。

---

### **4. 自定義和小眾模型**

- **Magochi**/**Mochi**: 為角色生成或小眾藝術設計優化。
- **Illustrious**: 專注於插圖、卡通與商業設計。

---

### **5. 其他變體**

- **Flux.1 S/D**: 強化動態內容與細節處理，適合商業視頻和高精度圖像生成。
- **SVD**: 強調穩定性與多樣性平衡的模型。

---

### **如何選擇模型**

選擇模型時，應根據需求與硬件資源進行選擇：

1. **高分辨率需求**：選擇 **SDXL 1.0** 或 **SDXL Hyper**。
2. **資源有限**：選擇 **SD 1.5 LCM** 或 **SDXL Lightning**。
3. **動漫/插畫風格**：選擇 **PixArt Σ** 或 **PixArt A**。
4. **視頻生成**：選擇 **CogVideoX** 或 **Hunyuan Video**。
5. **藝術氛圍設計**：選擇 **Aura Flow** 或 **Kolors**。

## Model Type

以下是各種模型類型和相關技術的分類與解釋：

### **1. 模型類型**

#### **1.1 Checkpoint**

- **定義**：完整的預訓練模型檔案，包含所有的權重、配置和必要的數據。
- **用途**：提供完整的模型架構和參數，用於直接生成圖像。
- **特點**：
  - 通常較大（數 GB）。
  - 提供基礎能力，可搭配其他模型（如 LoRA 或 ControlNet）。

#### **1.2 LoRA**

- **定義**：使用 **低秩適配（Low-Rank Adaptation）** 技術的輕量級模型，針對特定任務進行微調。
- **用途**：讓模型快速適配特定風格或內容，減少微調時間與存儲需求。
- **特點**：
  - 文件體積小（幾十 MB）。
  - 需搭配基礎模型（Checkpoint）使用。

#### **1.3 VAE (Variational Autoencoder)**

- **定義**：一種數據壓縮和重建的模型，負責將圖像數據壓縮到潛在空間並重建為清晰圖像。
- **用途**：
  - 在圖像生成過程中增強細節。
  - 解決模糊或顏色異常問題。
- **特點**：
  - 常與 Checkpoint 或其他模型一起使用。

#### **1.4 Embedding**

- **定義**：詞向量嵌入，用於優化模型的文本理解能力。
- **用途**：使模型更準確地理解特定的語義或風格。
- **特點**：
  - 文件體積小。
  - 常用於增強文本提示效果。

#### **1.5 LyCORIS**

- **定義**：LoRA 的變體，提供更多的自由度和控制。
- **用途**：微調模型，適應更複雜的風格或結構變化。
- **特點**：
  - 支援更細緻的調整。
  - 與 LoRA 類似，但更加靈活。

#### **1.6 Hypernetwork**

- **定義**：附加於基礎模型的次級網絡，用於影響生成風格。
- **用途**：快速切換風格或適配特定的生成需求。
- **特點**：
  - 文件小，靈活性高。
  - 需要與基礎模型搭配。

#### **1.7 ControlNet**

- **定義**：一種可控生成技術，允許用戶指定圖像的結構或特定元素。
- **用途**：例如改變姿勢、控制輪廓或參考草圖。
- **特點**：
  - 強大的可控性。
  - 與基礎模型一起運行。

### **2. 工具與技術**

#### **2.1 Aesthetic Gradient**

- **定義**：一種計算和應用圖像審美評分的技術，用於優化生成效果。
- **用途**：幫助生成更符合審美的圖像。

#### **2.2 Upscaler**

- **定義**：圖像放大技術，用於增強圖像分辨率和細節。
- **用途**：提升低分辨率圖像的清晰度。

#### **2.3 Wildcards**

- **定義**：自動化生成技術，允許隨機替換提示中的某些元素。
- **用途**：創建多樣化的生成結果。

### **3. 特殊用途模型**

#### **3.1 Motion**

- **定義**：專注於生成運動或動態效果的模型。
- **用途**：用於視頻生成或動態場景創作。

#### **3.2 Poses**

- **定義**：一類生成或控制角色姿勢的模型或數據集。
- **用途**：適合角色設計與動態構圖。

#### **3.3 DORA**

- **定義**：可能是專為某些藝術風格或應用場景設計的模型。
