---
icon: pen-to-square
date: 2024-08-02
category:
  - AI
tag:
  - nlp
---
# Zero-Shot Classification

Zero-shot classification æ˜¯ä¸€ç¨®è‡ªç„¶èªè¨€è™•ç†ä»»å‹™ï¼Œæ¨¡å‹åœ¨è¨“ç·´æ™‚ä½¿ç”¨ä¸€çµ„æ¨™è¨˜ç¤ºä¾‹ï¼Œä½†èƒ½å¤ åˆ†é¡ä¾†è‡ªä¹‹å‰æœªè¦‹é¡åˆ¥çš„æ–°ç¤ºä¾‹ã€‚

## å…§å®¹æ¦‚è¿°

### 1. ä»€éº¼æ˜¯Zero-Shot Classificationï¼Ÿ

é›¶-shotåˆ†é¡æ˜¯ä¸€ç¨®é æ¸¬æ¨¡å‹åœ¨è¨“ç·´æœŸé–“æœªè¦‹éçš„é¡åˆ¥çš„æ–¹æ³•ã€‚é€™ç¨®æ–¹æ³•åˆ©ç”¨é è¨“ç·´çš„èªè¨€æ¨¡å‹ï¼Œå¯ä»¥è¦–ç‚ºè½‰ç§»å­¸ç¿’çš„ä¸€ç¨®å½¢å¼ï¼Œç‰¹åˆ¥é©ç”¨æ–¼æ¨™è¨˜æ•¸æ“šé‡è¼ƒå°çš„æƒ…æ³ã€‚

Zero-Shot Learningï¼ˆZSLï¼‰æ˜¯ä¸€ç¨®åœ¨è¨“ç·´éç¨‹ä¸­æœªè¦‹éæŸäº›é¡åˆ¥çš„æ¨£æœ¬ï¼Œä½†èƒ½å¤ åœ¨æ¸¬è©¦éšæ®µå°é€™äº›é¡åˆ¥é€²è¡Œåˆ†é¡çš„æŠ€è¡“ã€‚é€™ç¨®å­¸ç¿’æ–¹å¼é€šå¸¸ä¾è³´è¼”åŠ©ä¿¡æ¯ä¾†é€²è¡Œæ¨æ–·ã€‚

### 2. è¼”åŠ©ä¿¡æ¯çš„é¡å‹

1. **å±¬æ€§æè¿°**
    - é¡åˆ¥å¯ä»¥ç”¨ä¸€çµ„é å®šç¾©çš„å±¬æ€§ä¾†æè¿°ï¼Œä¾‹å¦‚ã€Œé•·é¬ƒã€ã€ã€Œæœ‰æ–‘é»ã€ç­‰ã€‚
    - å±¬æ€§é€šå¸¸ä»¥çµæ§‹åŒ–çš„æ–¹å¼çµ„ç¹”ï¼Œé€™æ¨£å¯ä»¥æé«˜å­¸ç¿’çš„æ•ˆç‡å’Œæº–ç¢ºæ€§ã€‚
    - é€™ç¨®æ–¹æ³•åœ¨è¨ˆç®—æ©Ÿè¦–è¦ºä¸­æ‡‰ç”¨å»£æ³›ï¼Œä¸¦ä¸”åœ¨è‡ªç„¶èªè¨€è™•ç†ä¸­ä¹Ÿæœ‰ä¸€äº›ä¾‹å­ã€‚
2. **æ–‡æœ¬æè¿°**
    - é¡åˆ¥æ¨™ç±¤è¢«è¦–ç‚ºå…·æœ‰èªç¾©æ„ç¾©ï¼Œé€šå¸¸æœƒé™„åŠ å®šç¾©æˆ–è‡ªç„¶èªè¨€æè¿°ï¼Œä¾‹å¦‚å¾ç¶­åŸºç™¾ç§‘ç²å–çš„é¡åˆ¥æè¿°ã€‚
    - æ­¤æŠ€è¡“åœ¨è‡ªç„¶èªè¨€è™•ç†ä¸­å°¤ç‚ºé‡è¦ï¼Œå› ç‚ºå®ƒå¹«åŠ©æ¨¡å‹ç†è§£é¡åˆ¥çš„å«ç¾©ã€‚
3. **é¡åˆ¥ç›¸ä¼¼åº¦**
    - å°‡é¡åˆ¥åµŒå…¥åˆ°ä¸€å€‹é€£çºŒçš„ç‰¹å¾µç©ºé–“ä¸­ï¼Œé€šéé æ¸¬æ¨£æœ¬åœ¨è©²ç©ºé–“ä¸­çš„ä½ç½®ä¾†é€²è¡Œåˆ†é¡ã€‚
    - é›–ç„¶åœ¨è¨“ç·´éç¨‹ä¸­æœªè§€å¯Ÿåˆ°æŸäº›é¡åˆ¥çš„æ¨£æœ¬ï¼Œä½†å¯ä»¥åˆ©ç”¨å·²çŸ¥é¡åˆ¥çš„ç‰¹å¾µä¾†æ¨æ–·æ–°é¡åˆ¥çš„ç‰¹å¾µã€‚

### 3. æ¨¡å‹æ¶æ§‹
Zero-Shot Learningæ¨¡å‹é€šå¸¸åŒ…æ‹¬å…©å€‹ä¸»è¦çµ„ä»¶ï¼š
1. **ç‰¹å¾µå­¸ç¿’æ¨¡å¡Š**ï¼šå­¸ç¿’å¦‚ä½•å¾è¼¸å…¥æ•¸æ“šä¸­æå–ç‰¹å¾µï¼Œé€™äº›ç‰¹å¾µç”¨æ–¼æè¿°é¡åˆ¥ã€‚
2. **æ¨æ–·æ¨¡å¡Š**ï¼šåˆ©ç”¨è¼”åŠ©ä¿¡æ¯ä¾†é€²è¡Œé¡åˆ¥æ¨æ–·ï¼Œé€šå¸¸æ¶‰åŠå°‡è¼¸å…¥æ¨£æœ¬çš„ç‰¹å¾µèˆ‡é¡åˆ¥çš„è¼”åŠ©ä¿¡æ¯é€²è¡Œæ¯”å°ã€‚

### 4. å»£ç¾©Zero-Shot Learning

åœ¨é€™ç¨®è¨­ç½®ä¸­ï¼Œæ¸¬è©¦æ™‚å¯èƒ½æœƒåŒæ™‚å‡ºç¾æ–°é¡åˆ¥å’Œå·²çŸ¥é¡åˆ¥çš„æ¨£æœ¬ã€‚é€™è¦æ±‚åˆ†é¡å™¨èƒ½å¤ åˆ¤æ–·ä¸€å€‹æ¨£æœ¬æ˜¯ä¾†è‡ªæ–¼æ–°é¡åˆ¥é‚„æ˜¯å·²çŸ¥é¡åˆ¥ã€‚

#### è§£æ±ºæ–¹æ¡ˆ

1. **é–˜æ§æ¨¡å¡Š**ï¼š
    - è¨“ç·´ä¸€å€‹æ¨¡å‹ä¾†åˆ¤æ–·æ¨£æœ¬ä¾†è‡ªæ–°é¡åˆ¥é‚„æ˜¯èˆŠé¡åˆ¥ï¼Œä¸¦åœ¨æ¨æ–·æ™‚è¼¸å‡ºç¡¬æ±ºç­–æˆ–è»Ÿæ¦‚ç‡æ±ºç­–ã€‚
2. **ç”Ÿæˆæ¨¡å¡Š**ï¼š
    - ç”Ÿæˆæœªè¦‹é¡åˆ¥çš„ç‰¹å¾µè¡¨ç¤ºï¼Œä¸¦ä½¿ç”¨æ¨™æº–åˆ†é¡å™¨å°æ‰€æœ‰é¡åˆ¥ï¼ˆåŒ…æ‹¬å·²è¦‹å’Œæœªè¦‹çš„ï¼‰é€²è¡Œè¨“ç·´ã€‚

### 5. æŠ€è¡“æŒ‘æˆ°

1. **é¡åˆ¥é–“çš„ç›¸ä¼¼æ€§**ï¼šå¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨é¡åˆ¥ä¹‹é–“çš„ç›¸ä¼¼æ€§ä¾†é€²è¡Œæ¨æ–·ã€‚
2. **è¼”åŠ©ä¿¡æ¯çš„è³ªé‡**ï¼šè¼”åŠ©ä¿¡æ¯çš„è³ªé‡å’Œçµæ§‹ç›´æ¥å½±éŸ¿åˆ†é¡çš„æº–ç¢ºæ€§ã€‚
3. **æ¨£æœ¬ä¸å¹³è¡¡**ï¼šåœ¨æŸäº›æƒ…æ³ä¸‹ï¼Œå·²çŸ¥é¡åˆ¥çš„æ¨£æœ¬å¯èƒ½é å¤šæ–¼æœªè¦‹é¡åˆ¥çš„æ¨£æœ¬ï¼Œé€™æœƒå½±éŸ¿æ¨¡å‹çš„å­¸ç¿’æ•ˆæœã€‚

### 6. æ‡‰ç”¨å¯¦ä¾‹

1. **åœ–åƒåˆ†é¡**ï¼šèƒ½å¤ è­˜åˆ¥æœªè¦‹éçš„å‹•ç‰©é¡åˆ¥ï¼Œä¾‹å¦‚è¨“ç·´æ¨¡å‹è­˜åˆ¥é¦¬ï¼Œä½†èƒ½å¤ æ¨æ–·æ–‘é¦¬çš„é¡åˆ¥ã€‚
2. **èªç¾©åˆ†å‰²**ï¼šå°æ–¼æœªè¦‹éçš„ç‰©é«”é¡åˆ¥é€²è¡Œåˆ†å‰²ï¼Œä½¿ç”¨è¼”åŠ©ä¿¡æ¯ä¾†æŒ‡å°åˆ†å‰²éç¨‹ã€‚
3. **è‡ªç„¶èªè¨€è™•ç†**ï¼šåœ¨æ–‡æœ¬åˆ†é¡ä¸­ï¼Œæ¨¡å‹èƒ½å¤ æ ¹æ“šæ–‡æœ¬æè¿°é€²è¡Œåˆ†é¡ï¼Œç„¡éœ€æä¾›æ¨£æœ¬æ•¸æ“šã€‚

## å¯¦ç¾æ–¹æ³•

### è©åµŒå…¥ï¼ˆWord Embeddingsï¼‰

- è©åµŒå…¥æ˜¯å°‡å–®è©æ˜ å°„åˆ°é«˜ç¶­å‘é‡ç©ºé–“ä¸­çš„æ–¹æ³•ã€‚å¸¸è¦‹çš„è©åµŒå…¥æŠ€è¡“åŒ…æ‹¬ Word2Vecã€GloVeã€BERTã€GPT ç­‰ã€‚é€™äº›æŠ€è¡“èƒ½å¤ æ•æ‰å–®è©ä¹‹é–“çš„èªç¾©é—œä¿‚ï¼Œå¾è€Œåœ¨å‘é‡ç©ºé–“ä¸­è¡¨ç¤ºå–®è©çš„èªç¾©ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼ŒWord2Vecå’ŒGloVeä¸»è¦ç”¨æ–¼éœæ…‹è©åµŒå…¥ï¼Œè€ŒBERTå’ŒGPTæ˜¯å‹•æ…‹è©åµŒå…¥ï¼Œèƒ½å¤ æ ¹æ“šä¸Šä¸‹æ–‡å‹•æ…‹èª¿æ•´è©çš„è¡¨ç¤ºã€‚
- åœ¨é›¶æ¨£æœ¬åˆ†é¡ä¸­ï¼Œè©åµŒå…¥ç”¨æ–¼å°‡é¡åˆ¥æ¨™ç±¤å’Œæ–‡æœ¬æè¿°è½‰æ›ç‚ºå‘é‡ï¼Œç„¶å¾Œæ¯”è¼ƒé€™äº›å‘é‡çš„ç›¸ä¼¼åº¦ã€‚

### è‡ªç„¶èªè¨€ç†è§£ï¼ˆNatural Language Understanding, NLUï¼‰

- NLU æ˜¯ NLP çš„ä¸€éƒ¨åˆ†ï¼Œæ—¨åœ¨ä½¿æ©Ÿå™¨ç†è§£å’Œè§£é‡‹äººé¡èªè¨€ã€‚é€™åŒ…æ‹¬èªç¾©è§£æã€æƒ…æ„Ÿåˆ†æã€ä¸»é¡Œå»ºæ¨¡ç­‰ã€‚
- é›¶æ¨£æœ¬åˆ†é¡éœ€è¦ NLU æŠ€è¡“ä¾†ç†è§£æ–°é¡åˆ¥çš„æè¿°ï¼Œä¸¦å°‡å…¶è½‰æ›ç‚ºåˆé©çš„å‘é‡è¡¨ç¤ºã€‚

### è·¨æ¨¡æ…‹å­¸ç¿’ï¼ˆCross-Modal Learningï¼‰

- è·¨æ¨¡æ…‹å­¸ç¿’æ¶‰åŠå¾ä¸åŒçš„æ•¸æ“šæ¨¡æ…‹ï¼ˆå¦‚æ–‡æœ¬ã€åœ–åƒã€éŸ³é »ï¼‰ä¸­å­¸ç¿’å…±äº«è¡¨ç¤ºã€‚é€™åœ¨é›¶æ¨£æœ¬åˆ†é¡ä¸­ç‰¹åˆ¥é‡è¦ï¼Œå› ç‚ºæ¨¡å‹éœ€è¦å°‡æ–‡æœ¬æè¿°å’Œé¡åˆ¥æ¨™ç±¤é€²è¡Œèªç¾©å°é½Šã€‚
- é€šéå…±äº«çš„å‘é‡ç©ºé–“ï¼Œæ¨¡å‹å¯ä»¥æ¯”è¼ƒä¸åŒæ¨¡æ…‹çš„æ•¸æ“šï¼Œé€²è¡Œç›¸ä¼¼æ€§è©•ä¼°ã€‚

### é€šç”¨èªè¨€æ¨¡å‹ï¼ˆUniversal Language Modelsï¼‰

- ä½¿ç”¨é è¨“ç·´çš„é€šç”¨èªè¨€æ¨¡å‹ï¼ˆå¦‚ BERTã€GPT-3ï¼‰ï¼Œé€™äº›æ¨¡å‹å·²ç¶“åœ¨å¤§é‡æ–‡æœ¬æ•¸æ“šä¸Šé€²è¡Œäº†é è¨“ç·´ï¼Œå…·æœ‰å¼·å¤§çš„èªç¾©ç†è§£èƒ½åŠ›ã€‚
- é€šéå¾®èª¿ï¼ˆfine-tuningï¼‰æˆ–ç›´æ¥ä½¿ç”¨é è¨“ç·´æ¨¡å‹ï¼Œå¯¦ç¾é›¶æ¨£æœ¬åˆ†é¡ã€‚

### å°æ¯”å­¸ç¿’ï¼ˆContrastive Learningï¼‰

- ä½¿ç”¨å°æ¯”å­¸ç¿’æŠ€è¡“ï¼Œé€šéå­¸ç¿’å°‡ç›¸ä¼¼çš„æ•¸æ“šé»é è¿‘ï¼Œä¸ç›¸ä¼¼çš„æ•¸æ“šé»åˆ†é–‹ï¼Œä¾†å¢å¼·æ¨¡å‹çš„åˆ†é¡èƒ½åŠ›ã€‚
- é€™ç¨®æŠ€è¡“åœ¨é›¶æ¨£æœ¬å­¸ç¿’ä¸­å¯ä»¥æœ‰æ•ˆåˆ©ç”¨æœ‰é™çš„æ¨™è¨˜æ•¸æ“šï¼Œå¢å¼·æ¨¡å‹åœ¨æ–°é¡åˆ¥ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

### æ¨æ–·

å¯ä»¥ä½¿ç”¨ğŸ¤— Transformersåº«ä¸­çš„é›¶-shotåˆ†é¡ç®¡é“é€²è¡Œæ¨æ–·ï¼š

```python
from transformers import pipeline

pipe = pipeline(model="facebook/bart-large-mnli")
pipe("I have a problem with my iphone that needs to be resolved asap!",
    candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"])
# output
# >>> {'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

## æ³¨æ„äº‹é …

1. **æ•¸æ“šè³ªé‡**
   - é›–ç„¶é›¶æ¨£æœ¬åˆ†é¡ä¸ä¾è³´å¤§é‡æ¨™è¨˜æ•¸æ“šï¼Œä½†éœ€è¦é«˜è³ªé‡çš„æ–‡æœ¬æè¿°å’Œé¡åˆ¥æ¨™ç±¤ã€‚
   - é€™äº›æè¿°æ‡‰è©²æ¸…æ™°ä¸”å…·æœ‰ä»£è¡¨æ€§ï¼Œä»¥æé«˜åˆ†é¡çš„æº–ç¢ºæ€§ã€‚

2. **æ¨¡å‹é¸æ“‡**
   - é¸æ“‡åˆé©çš„é è¨“ç·´æ¨¡å‹æ˜¯æˆåŠŸçš„é—œéµã€‚
   - ä¸åŒçš„èªè¨€æ¨¡å‹åœ¨ä¸åŒçš„ä»»å‹™ä¸Šæ€§èƒ½å¯èƒ½æœ‰æ‰€ä¸åŒï¼Œéœ€æ ¹æ“šå…·é«”æ‡‰ç”¨å ´æ™¯é¸æ“‡æœ€åˆé©çš„æ¨¡å‹ã€‚

3. **å€™é¸æ¨™ç±¤çš„é¸æ“‡**
   - ç¢ºä¿å€™é¸æ¨™ç±¤èˆ‡å¾…åˆ†é¡æ–‡æœ¬çš„å…§å®¹ç›¸é—œã€‚
   - é¿å…ç„¡é—œæ¨™ç±¤å°çµæœçš„å¹²æ“¾ï¼Œä»¥æé«˜åˆ†é¡çš„æº–ç¢ºæ€§ã€‚

4. **æ–‡æœ¬é è™•ç†**
   - å°å¾…åˆ†é¡çš„æ–‡æœ¬é€²è¡Œå¿…è¦çš„é è™•ç†ï¼Œå¦‚å»é™¤å¤šé¤˜çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ã€‚
   - é€™èƒ½æå‡åˆ†é¡æ•ˆæœã€‚

5. **èªç¾©ç›¸ä¼¼åº¦è¨ˆç®—**
   - è¨ˆç®—æ–‡æœ¬æè¿°èˆ‡é¡åˆ¥æ¨™ç±¤ä¹‹é–“çš„ç›¸ä¼¼åº¦æ˜¯é›¶æ¨£æœ¬åˆ†é¡çš„é‡è¦ç’°ç¯€ã€‚
   - å¸¸ç”¨çš„æ–¹æ³•åŒ…æ‹¬é¤˜å¼¦ç›¸ä¼¼åº¦ã€é»ç©å’Œæ­æ°è·é›¢ç­‰ã€‚
   - é¸æ“‡åˆé©çš„ç›¸ä¼¼åº¦è¨ˆç®—æ–¹æ³•èƒ½æé«˜åˆ†é¡çš„æº–ç¢ºæ€§ã€‚

## Reference
- Word2Vec: Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space.
- GloVe: Pennington, J., Socher, R., & Manning, C. D. (2014). GloVe: Global Vectors for Word Representation.
- BERT: Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.
- GPT-3: Brown, T. B., et al. (2020). Language Models are Few-Shot Learners.
- Zero-Shot Learning with BERT: Blog on using BERT for Zero-Shot Learning
- Contrastive Learning: Chen, T., et al. (2020). A Simple Framework for Contrastive Learning of Visual Representations.